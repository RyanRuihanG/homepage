<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Ruihang Chu</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <!script src="assets/js/html5shiv.js"></script -->
</head>

<div class="visible-phone" id="blackBar">
    <a href="#top">About</a>
    <!--<a href="#research">Research</a>-->
    <a href="#Research">Research</a>
    <a href="#projects">Projects</a>
    <!--<a href="#teaching">Teaching</a>-->
 </div>

<body>

<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <li><a href="#Educations">Educations</a></li>
            <li><a href="#Internships">Internships</a></li>
            <li><a href="#Research">Research</a></li>
            <li><a href="#Projects">Projects</a></li>
            <li><a href="#Honors & Scholarships">Honors & Scholarships</a></li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center pull-left hidden-phone">
            <img src="assets_files/ruihang_new.png" alt="photo" width="237px" height="158px" class="logo-image">
            <br>
            churuihang@buaa.edu.cn

        </div>

        <!-- Otherwise, we simply use a flat list of links -->

    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                Ruihang Chu (储瑞航)
            </h3>

            <p>
                I received the B.E, degree in mechanical engineering and automation from Beihang University, Beijing, China in 2017. Currently, I am working towards a M.E. degree in the Robotics Institute, Beihang University. My research interests include intelligent Robotics, haptics and human-robot interaction. Meanwhile, I work as an intern in video research group, Megvii Technology (Face ++) from Sep, 2018 to now. My research revolves around computer vision and deep learning here, mainly looking to explore new method to tackle vehicle re-identification problem. 
<!--                 <a target="_blank" href="https://scholar.google.com/citations?user=yuB-cfoAAAAJ&hl=zh-CN">Xiangyu Zhang</a> to do research in object detection and neural architecture search. -->
             </p>

            <!--
             *** Research ***
            -->
            <!--<h3>-->
            <!--<a name="research"></a> Research-->
            <!--</h3>-->
            <!--<p>-->
            <!--My current research topics include:-->
            <!--</p><ul>-->
            <!--<li> Learning better structures for image feature extraction.-->
            <!--</li><li> Explaining human generalization behavior with visually grounded cogscience models.-->
            <!--</li><li> Making large-scale vision feasible and affordable.-->
            <!--</li></ul>-->
            <!--<p></p>-->
            <!--<p> (Most recent publications to be added) </p>-->

            <!--
             *** Research ***
            -->
            <h3>
                <a name="Educations"></a> Educations
            </h3>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [Sep 2017 - Jun 2020]
                        <strong>
                            Robotics Institute, Beihang University
                            
                        </strong>
                    </p>
                    <p class="abstract-text">
                    M.Eng, <a target="_blank" href="http://haptic.buaa.edu.cn/">Human-machine Interaction Laboratory</a>, <a target="_blank" href="http://vrlab.buaa.edu.cn/">State Key Laboratory of Virtual Reality Technology and Systems</a>. Advisors: <a target="_blank" href="http://haptic.buaa.edu.cn/chinese_team_teacherZhang.htm">Yuru Zhang</a> <br />
                    Do research in haptic human-robot interaction, GPA: 3.81/4.0
                    </p>
                </div>
            </div>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [Sep 2013 - Jun 2017]
                        <strong>
                            School of Mechanical Engineering and Automation, Beihang University
                        </strong>
                    </p>
                    <p class="abstract-text">
                    B.Eng, Major in Mechatronics, Ranking 7/209, GPA: 3.7/4.0
                    </p>
                </div>
            </div>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [Feb 2017 - May 2017]
                        <strong>
                            Politecnico di Torino
                        </strong>
                    </p>
                    <p class="abstract-text">
                    Exchange study
                    </p>
                </div>
            </div>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [August 2016 - November 2016]
                        <strong>
                            Seoul National University, HKUST, Tsinghua University
                        </strong>
                    </p>
                    <p class="abstract-text">
                        Visiting study
                    </p>
                </div>
            </div>

            <h3>
                <a name="Internships"></a> Internships
            </h3>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [Sep 2018 - now]
                        <strong>
                            Megvii Technology (Face++)
                        </strong>
                    </p>
                    <p class="abstract-text">
                    Work with Chi Zhang <br />
                    Do research in re-identification tasks, especially in vehicle re-identification.
                    </p>
                </div>
            </div>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [July 2018 - Sep 2018]
                        <strong>
                            Yizhun-ai Technology
                        </strong>
                    </p>
                    <p class="abstract-text">
                    Do engineering projects for thick lung nodule detection.
                    </p>
                </div>
            </div>
            
            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [July 2018 - Aug 2018]
                        <strong>
                            Deecamp
                        </strong>
                    </p>
                    <p class="abstract-text">
                    Become one of 300 selected candidates from 7000 applicants to join the Deecamp AI summer camp sponsored by Dr.Kai-Fu Lee and Peking University. Do engineering projects for human flow tracking and win the 2nd prize among 28 groups.
                    </p>
                </div>
            </div>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        [Nov 2017 - Dec 2017]
                        <strong>
                            Sohu 
                        </strong>
                    </p>
                    <p class="abstract-text">
                    Do engineering projects to help build the smart recommendation platform. 1、Head image cropping based on object detection. 2、Web crawler system building.
                    </p>
                </div>
            </div>



            <!--
             *** Research ***
            -->
            <h3>
                <a name="Research"></a> Research
            </h3>
            <div class="media">
                <a name="softer" class="pull-left">
                    <img class="media-object" src="assets_files/vehiclereid.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             ICCV2019 Anonymous Submission
                     </strong><br>
                        <b>Ruihang Chu</b>, Yifan Sun, Yadong Li, Zheng Liu, Chi Zhang*, Yichen Wei.
                    </p>
                    <p class="abstract-text">
                        - The first work to propose a challenging problem, i.e., the extreme viewpoint variation (up to 180 degrees) in vehicle re-identification. <br />
                        - Tackle the proposed problem from a new perspective. <br />
                        - Achieve the state-of-the-art performance in two public dataset: VehicleID and Veri776.
                    </p>
                </div>
            </div>
         <div class="media">
                <a name="softer" class="pull-left">
                    <img class="media-object" src="assets_files/toh.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Co-actuation: A Method for Achieving High Stiffness and Low Inertia for Haptic Devices
                            <!-- 
<a target="_blank" href="https://arxiv.org/abs/1901.05884">[arXiv]</a>
                            <a target="_blank" href="https://github.com/JaminFong/EAT-NAS">[code]</a>
 -->
                     </strong><br>
                        <b>Ruihang Chu</b>, Yuru Zhang, Hongdong Zhang, Dangxiao Wang*, Weiliang Xu, Jee-Hwan Ryu.<br />
                        Submitted to IEEE Transactions on Haptics(JIF=2.757). Status: Major revision. Submitted the revision on May 1, 2019
                    </p>
                    <p class="abstract-text">
                        - It is difficult to stimulate hard contact and small inertia simultaneously in virtual environment for haptic device.<br />
                        - Introduce a co-actuation module to overcome this difficulty.<br />
                        - Demonstrate the effectiveness of co-actuation on a 2-DOF haptic device.<br />
                        - The device can render a virtual wall with the stiffness as high as 65N/mm. The effective inertia is 35-145g. <br />
                    </p>
                </div>
            </div>
         <div class="media">
                <a name="address" class="pull-left">
                    <img class="media-object" src="assets_files/dentaltouch.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             A Haptic Device with High stiffness and Low Inertia Based on Co-actuation Principle
                            <!-- 
<a target="_blank"
                           href="https://arxiv.org/abs/1811.09426">[arXiv]</a>
                            <a target="_blank"
                           href="https://github.com/yukang2017/NAS-quantization">[code]</a>
 -->
                     </strong><br>
                            <b>Ruihang Chu</b>, Yuru Zhang*, Hongdong Zhang <br />
                            Accepted by Annual Conference of Chinese Robotics Society<br />
                            (The mechanism was authorized by Chinese Patent: ZL 2016 1 0941924.0, 2017)
                    </p>
                    <p class="abstract-text">
                       - Introduce a 3-DOF haptic device named DentalTouch to provide both high stiffness and low inertia. <br />
                       - Describe the design of prototype, the modeling of the effective inertia and the control scheme. <br />
                       - The device can render a virtual wall with the stiffness as high as 67N/mm. The effective inertia is 180-201g.<br />
                    </p>
                </div>
            </div> 
        <div class="media">
                <a name="AMC" class="pull-left">
                    <img class="media-object" src="./assets_files/blank.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             The Submitted Paper
                            <!-- 
<a target="_blank"
                           href="https://arxiv.org/abs/1808.00193">[arXiv]</a>
                            <a target="_blank"
                           href="https://github.com/yukang2017/RENAS">[code]</a>
 -->
                     </strong><br>
                        Ran Jiao*, Zhaowei Wang, <b>Ruihang Chu</b> <br />
						Submitted to Frontiers in Neurorobtics(JIF=3.000).
                    </p>
                    <p class="abstract-text">
                        - Exploit the deep human pose estimation to guide human-drone interaction in the wild.
                        <br />
                        - Fit the network to mobile settings and achieve realtime interaction. 
                        <br />
                        - Robust to the disturbance from wilderness environment.
                    </p>
                </div>
            </div>

            <!--
             *** Projects ***
            -->
            <h3>
                <a name="Projects"></a> Projects
            </h3>
         <div class="media">
                <a name="softer" class="pull-left">
                    <img class="media-object" src="assets_files/deecamp.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Human Flow Tracking System (Team Leader)
                             <a target="_blank" href="https://v.youku.com/v_show/id_XMzkyOTc4MTQ1Mg==.html?refer=seo_operation.liuxiao.liux_00003307_3000_z2iuq2_19042900">[Demo]</a>
                     </strong><br>
                    </p>
                    <p class="abstract-text">
                        We develop a real-time software system for human flow tracking. It can be applied in new retail industry. The technologies involve pedestrian detection, re-identification and multiple object tracking.
                </div>
            </div>
            
        <div class="media">
                <a name="softer" class="pull-left">
                    <img class="media-object" src="assets_files/tianchi.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                        IJCAI-19 Alibaba Adversarial AI Challenge
<!--                         <a target="_blank" href="https://v.youku.com/v_show/id_XMzkyOTc4MTQ1Mg==.html?refer=seo_operation.liuxiao.liux_00003307_3000_z2iuq2_19042900">[Code]</a> -->

                     </strong><br>
                    </p>
                    <p class="abstract-text">
                    We implement PNASNet-5 as backbone to improve recognition performance. We train our defense model at the presence of adversarial samples generated by fast gradient sign method. Moreover, we re-detect the objects with a tighter bbox to overcome the disturbance from the background. We rank 36th among 2520 teams in the finals.
                </div>
            </div>

         <div class="media">
                <a name="address" class="pull-left">
                    <img class="media-object" src="assets_files/rosrobot.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            An Intelligent Robot based on Ros and Android System (Team Leader)
                            <a target="_blank"
                           href="https://youtu.be/0Son0Zwq-hk">[Code]</a>
                            <a target="_blank"
                           href="https://v.qq.com/x/page/y0192jvj6wb.html">[Demo]</a>
                        </strong><br>
                    </p>
                    <p class="abstract-text">
                       We propose to replace the expensive sensors by one android phone when making intelligent robot. Equipped with our provided robot chassis and software system, any Android owner has access to develop his/her personal robot. We believe it makes developing robots more approachable for robot fans. Specifically, we obtain the measured data from phone sensors, processing the data with ROS and delivering it to STM32, which serves as the controller. Finally, our robot integrates functions such as object tracking, speech recognition and grabbing. This project won the first prize in China Intelligent Product Design Competition in 2015.
                    </p>
                </div>
            </div>
            
            <div class="media">
                <a name="address" class="pull-left">
                    <img class="media-object" src="assets_files/kinect.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Control the 3-DOF worktable through a Kinect (Team Leader)
                            <a target="_blank"
                           href="https://youtu.be/0Son0Zwq-hk">[Code]</a>
                            <a target="_blank"
                           href="https://v.youku.com/v_show/id_XNDI2NjAwMDQ1Ng==.html?spm=a2hzp.8244740.0.0">[Demo]</a>
                        </strong><br>
                    </p>
                    <p class="abstract-text">
                    We develop a mechatronic control system based on Kinect and 3-DOF worktable. The system obtains the real-time position of human key points from Kinect, and then records the trajectory of human hands. The trajectory will be converted to the G code (the command in numerically controlled machine) through our plug-in components, which guides the 3-DOF worktable to draw the same trajectory.
                    </p>
                </div>
            </div>
            
            
             <div class="media">
                <a name="address" class="pull-left">
                    <img class="media-object" src="assets_files/robocon.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            China University Robot Competition
                        </strong><br>
                    </p>
                    <p class="abstract-text">
                    We develop two automatic robots which work cooperatively to overrun obstacles and climb the final pillar. We won the 3rd prize in national finals.
                    </p>
                </div>
            </div>
            
            <div class="media">
                <a name="address" class="pull-left">
                    <img class="media-object" src="assets_files/flycar.png" width="96px" height="96px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            A New Wall-climbing Robot 
                        </strong><br>
                    </p>
                    <p class="abstract-text">
                    When I was a visiting student in Seoul National University, HKUST and THU, we propose a new mechanism that enable robots to walk on the ground and climb the wall. We combine the wheel and paddle in one component. The novel scheme works theoretically yet needs further experimental verification. This project was reported by "I have heirlooms", the CCTV show, in Jul 16, 2017.
                    </p>
                </div>
            </div>
            
            
			<h3>
                <a name="Honors & Scholarships"></a> Honors & Scholarships
            </h3>

            <div class="media">
                <div class="media-body">
                    <p class="media-heading">
                        2017   Excellent Graduate Student of Beihang University <br />
                        2016   The third Prize of "National College Robot Competition" <br />
                        2015   The third Prize of "National College Robot Competition" <br />
                        2015   The first Prize of "China Intelligent Product Design Competition" <br />
                        2015   "Three-Good" Student of Beihang University <br />
                        <br />
                        
                        2018   The Second Prize of Beihang Postgraduate Students Scholarship  <br />
                        2017   The First Prize of Beihang Postgraduate Students Scholarship  <br />
                        2016   The First Prize of "AVI Industry" Scholarship  <br />
                        2015   The Second Prize of "OuPai" Scholarship  <br />
                        2015   The First Prize of Beihang "Science and Technology Innovation" Scholarship  <br />
                        2015   The Second Prize of Beihang "Learning Excellence" Scholarship  <br />
                        2014   The First Prize of "Timken" Scholarship  <br />
                    	2013   The Second Prize of "OuPai" Scholarship  <br />

                        
                
                    </p>
                </div>
            </div>

            
                </div>
            </div>


            <!-- Footer
            ================================================== -->

            <footer class="footer">
                <hr>
                <div class="row">
                    <div class="span12">
                        <p>
                            modified from <a target="_blank" href="http://yihui-he.github.io//">© Yihui He 2019</a>
                        </p>
                    </div>
                </div>

            </footer>

        </div>
    </div>
</div>
</body>
</html>
